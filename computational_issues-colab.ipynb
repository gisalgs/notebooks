{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/gisalgs/notebooks/blob/main/computational_issues-colab.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# Computational Issues of Spatial Indexing\n",
    "\n",
    "November 26, 2024\n",
    "\n",
    ">\"How long does getting thin take?\" asked Pooh anxiously.  \n",
    ">\"About a week, I should think.\"  \n",
    ">\"But I can't stay here for a *week*!\"  \n",
    ">\"You can *stay* all right, silly old Bear. It's getting you out which is so difficult.\"\n",
    ">\n",
    "><cite>A. A. Milne, Winnie-the-Pooh</cite>\n",
    "\n",
    ">\"And is all this common consciousness satisfied to use me as a black box? Since the black box works, is it unimportant to know what is inside? --- That doesn't suit me. I don't enjoy being a black box. I want to know what's inside.\"\n",
    ">\n",
    "><cite>Issac Asimov, Foundation and Earth</cite>\n",
    "\n",
    "\n",
    "The computational time for trees can be broken down to at least two parts. The first is the time used to construct the tree, and then it is the time the tree is used to query. The overall time complexity of building a balanced k-D tree is $O(n \\log_2 n)$. Searching a k-D only takes $O(\\log_2 n)$ time in average when the tree is balanced. For unbalanced trees, however, we can imagine a worst case where points are always aligned on one branch of the node and in this case the search time is $O(n)$, as same as the linear search (though the actual time might be longer because traversing a tree takes more time than traversing a list or an array).\n",
    "\n",
    "For point quadtrees, the cost of building a point quadtree is $O(n \\log_4 n)$ when points are randomly sorted before they are inserted to the tree as we discussed above. A simple search on a balanced point quadtree has a time complexity of $O(\\log_4 n)$ while the worst case would be $O(n)$ when the tree has only one node at each depth.\n",
    "\n",
    "The above discussion, however, is theoretical. In practice, the actual computational time may follow the overall trend as predicted, but there are also many other factors that have significant impacts on the performance. For example, the physical time used can vary a lot depending on whether the program is compiled into binary code (as C/C++ programs) or interpreted (as Python and Java). Generally speaking, interpreted programming languages such as Python are less efficient in terms of the actual running time because the code must be interpreted line by line. It should be noted that Python or Java is not the interpreted language in its original meaning where the interpreter literally goes through line by line for every time it runs the program. Instead, they often use an immediate representation of the code that is compiled in binary that runs faster. Still, interpreted languages are still generally slower than compiled languages such as C/C++. The difference may not be noticeable for small data (and probably we don't really care), but the difference will be big when we deal with large data sets. \n",
    "\n",
    "Aside from the programming language, how the algorithms are actually implemented will be a factor too. For example, the use of recursive functions, as convenient as it is, slows down the algorithm because of the repeated recursive function calls. \n",
    "\n",
    "The following are some commands that can be used in the notebook to get info about the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux, Max, or Colab\n",
    "!uname -a\n",
    "print()\n",
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows\n",
    "# !wmic cpu get caption, deviceid, name, numberofcores, maxclockspeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we can check the version of Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Performance of query using k-D trees and point quadtrees\n",
    "\n",
    "Here, we put our algorithms of k-D trees and point quadtrees into a test. We will simply compare the performance of using these trees, and we also compare them with the linear (brute-force) search approach. We test the performance by systematically controlling the size of the data and see how they catch up. The following are the packages that we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following if needed in Jupyter notebook to clone the github repos\n",
    "# !git clone https://github.com/gisalgs/geom.git\n",
    "# !git clone https://github.com/gisalgs/indexing.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geom.point import *\n",
    "from indexing.kdtree1 import *\n",
    "from indexing.kdtree2a import *\n",
    "from indexing.kdtree3 import *\n",
    "from indexing.pointquadtree1 import *\n",
    "from indexing.pointquadtree3 import *\n",
    "\n",
    "from random import random, sample, uniform\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we write a function to do the testing. This function requires inputs of the number of points to be indexed in a tree, the number of points to be queried, and a boolean variable to specify if we need verbose (wordy) output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(npts, n, verbose=False):\n",
    "    points = [Point(random(), random()) for i in range(npts)]\n",
    "    time1 = time.time()\n",
    "    kdt1 = kdtree(points)\n",
    "    time2 = time.time()\n",
    "    treet1 = time2-time1\n",
    "    time1 = time.time()\n",
    "    kdt2 = kdtree2(points)\n",
    "    time2 = time.time()\n",
    "    treet2 = time2-time1\n",
    "    time1 = time.time()\n",
    "    kdt3 = pointquadtree(points)\n",
    "    time2 = time.time()\n",
    "    treet3 = time2-time1\n",
    "    \n",
    "    t1 = 0 # time finding n points in kdtree\n",
    "    t2 = 0 # time for balanced kdtree\n",
    "    t3 = 0 # time for point quadtree\n",
    "    t4 = 0 # time for linear search\n",
    "    pp = sample(points, n)\n",
    "    for p in pp:\n",
    "        time1 = time.time()\n",
    "        p1 = query_kdtree(kdt1, p)\n",
    "        time2 = time.time()\n",
    "        t1 = t1 + time2-time1\n",
    "\n",
    "        time1 = time.time()\n",
    "        p1 = query_kdtree(kdt2, p)\n",
    "        time2 = time.time()\n",
    "        t2 = t2 + time2-time1\n",
    "\n",
    "        time1 = time.time()\n",
    "        p1 = search_pqtree(kdt3, p)\n",
    "        time2 = time.time()\n",
    "        t3 = t3 + time2-time1\n",
    "\n",
    "        time1 = time.time()\n",
    "        for i in range(len(points)):\n",
    "            if p == points[i]:\n",
    "                break\n",
    "        time2 = time.time()\n",
    "        t4 = t4 + time2-time1\n",
    "\n",
    "    if verbose:\n",
    "        print(f'{npts:7} | {treet1:6.3f} {treet2:6.3f} {treet3:6.3f} | {t1:6.3f} {t2:6.3f} {t3:6.3f} | {t4:6.3f}')\n",
    "    return npts, treet1, treet2, treet3, t1, t2, t3, t4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a quick demo of this function in searching for 100 random points from 10,000 points. The test() function has an input called verbose which can be used to make the function run silently without printing anything. But printing out the current result can be a good feature if we want to know how the program progresses during time (for a long wait)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t1 = test(10000, 100, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above quick test clearly shows the efficiency of using the indexing method for query. It also shows that building the tree may need some significant amount of time. \n",
    "\n",
    "Now we give it a more systematical test. More specifically, we use different numbers of points, ranging from 100,000 to **1,000,000**, with a step of 100,000. All the experiments were done on Now we give it a more systematical test. More specifically, we use different numbers of points, ranging from 100,000 to **1,000,000**, with a step of 100,000. The experiments will be done on different systems (local or cloud) and the numbers will be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "time1 = time.time()\n",
    "n = 100\n",
    "alltime = []\n",
    "for npts in range(100000, 1000001, 100000):\n",
    "    alltime.append(test(npts, n, True))\n",
    "time2=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code reports some numbers, including the total time in minutes and the time used on tree, where almost all of that time are used to construct the tree (so using the tree doesn't take much time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = (time2-time1)/60\n",
    "t2 = sum([sum(alltime[i][1:]) for i in range(len(alltime))])/60\n",
    "t3 = sum([sum(alltime[i][1:7]) for i in range(len(alltime))])/60\n",
    "t4 = sum([sum(alltime[i][1:4]) for i in range(len(alltime))])/60\n",
    "print(f'total computing time: {t1:.1f} minutes')\n",
    "print(f'Total processing time: {t2:.1f} minutes')\n",
    "print(f'Total time on trees: {t3:.1f} minutes')\n",
    "print(f'Tree construction time: {t4:.1f} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a way of comparison, we can find [past results](https://github.com/gisalgs/notebooks/blob/main/computational-issues-past-results.md) at the github repo. It is interesting to see how performance varies among computers and even Python versions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plot the results for a better visualization of the difference in the performances. Here is a shot at the construction times used for different kinds of trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [ alltime[i][0]/1000 for i in range(len(alltime))]\n",
    "plt.plot(x, [ alltime[i][1] for i in range(len(alltime))], label='k-D tree')\n",
    "plt.plot(x, [ alltime[i][3] for i in range(len(alltime))], label = 'point quadtree')\n",
    "plt.plot(x, [ alltime[i][2] for i in range(len(alltime))], label='k-D tree (balanced)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Number of points (x1000)')\n",
    "plt.ylabel('Seconds')\n",
    "plt.title('Time for tree construction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benefit of using the tree for query is obvious:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, [ alltime[i][7] for i in range(len(alltime))], label='linear')\n",
    "plt.plot(x, [ alltime[i][4] for i in range(len(alltime))], label='k-D tree')\n",
    "plt.plot(x, [ alltime[i][6] for i in range(len(alltime))], label='point quadtree')\n",
    "plt.plot(x, [ alltime[i][5] for i in range(len(alltime))], label='k-D tree (balanced)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Number of points (x1000)')\n",
    "plt.ylabel('Seconds')\n",
    "plt.title('Time to query 100 points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trend of using the tree across the three trees is not clear based on the test we just did, but we can still see from below that the balanced k-D tree is clearly positioned at the bottom of the three curves, showing the efficiency of the balanced tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, [ alltime[i][4] for i in range(len(alltime))], label='k-D tree')\n",
    "plt.plot(x, [ alltime[i][6] for i in range(len(alltime))], label='point quadtree')\n",
    "plt.plot(x, [ alltime[i][5] for i in range(len(alltime))], label='k-D tree (balanced)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Number of points (x1000)')\n",
    "plt.ylabel('Seconds')\n",
    "plt.title('Time to query 100 points')\n",
    "plt.legend(loc='right', bbox_to_anchor=(1.45, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Performance of orthogonal range search\n",
    "\n",
    "We first define a few functions to make it convenient for testing different cases.\n",
    "\n",
    "A note on changes: the textbook (*GIS Algorithms*) has the following line to create random points. \n",
    "\n",
    "`randpoints0 = [Point(randrange(xmin, xmax), randrange(ymin, ymax)) for i in range(npts)]`\n",
    "\n",
    "However, `randrange` will only return integers which will likely produce duplicated points. Here we write a new function called `rand_point` that uses `random.uniform` to generate random points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A rectangle is defined as [ [xmin, xmax], [ymin, ymax]]\n",
    "\n",
    "def in_rect(p, rect):\n",
    "    x, y = p.x, p.y\n",
    "    if not (rect[0][0]>x or rect[0][1] < x or rect[1][0]>y or rect[1][1] < y):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def rectangular_linear(points, rect):\n",
    "    l = []\n",
    "    for p in points:\n",
    "        if in_rect(p, rect):\n",
    "            l.append(p)\n",
    "    return l\n",
    "\n",
    "def rand_point(rect):\n",
    "    '''generates a random point within a rect'''\n",
    "    x = uniform(rect[0][0], rect[0][1])\n",
    "    y = uniform(rect[1][0], rect[1][1])\n",
    "    return Point(x, y)\n",
    "\n",
    "def test_rect_find(w=10, h=10, rect=[[10,1000], [10,1000]], npts=100, n_query=10):\n",
    "    \"\"\"\n",
    "    Repeats n_query times, based on npts points.\n",
    "    Points are random in a area with both x and y ranging  from 10 to 1000.\n",
    "\n",
    "    Uses a balanced k-D tree.\n",
    "    Same set of points are used for n_query times.\n",
    "    Each time, find points in a tree of npts points in a rectangle of w wide and h high. \n",
    "    The rectangle does not go out of the range of x and y.\n",
    "    \n",
    "    Returns times of using the k-D tree and linear search, respectively.\n",
    "    The time is averaged per query.\n",
    "    \"\"\"\n",
    "    randpoints0 = [rand_point(rect) for i in range(npts)]\n",
    "    randpoints = copy.deepcopy(randpoints0)\n",
    "    kdt = kdtree2(randpoints0)\n",
    "\n",
    "    times = []\n",
    "    for i in range(n_query):\n",
    "        x1 = uniform(rect[0][0], rect[0][1]-w)\n",
    "        y1 = uniform(rect[1][0], rect[1][1]-h)\n",
    "        rect_target = [ [x1, x1+w], [y1, y1+h] ]\n",
    "        t1 = time.time()\n",
    "        found = []\n",
    "        range_query_orthogonal(kdt, rect_target, found)\n",
    "        t2 = time.time()\n",
    "        found2 = rectangular_linear(randpoints, rect_target) # linear search\n",
    "        t3 = time.time()\n",
    "        times.append( (t2-t1, t3-t2))\n",
    "    return sum([t[0] for t in times])/float(n_query), sum([t[1] for t in times])/n_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of using it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_rect_find(20, 20, npts=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that using a k-D tree will help rectangular query, but the increase of the rectangle size will increase the time used to query. We test two things here:\n",
    "\n",
    "1. when will the additional computation caused by the increase of the rectangle exceed the efficiency of using a k-D tree?\n",
    "2. what is the impact of increasing the problem size (total number of points)?\n",
    "\n",
    "We test the average of time used for each query for each configuration. The following code will take some significant time to run. It will be important to let the computer run, with power plugged in, and do not disturb it with other heavy lifting tasks such as watching movies or even gaming. We will be better off by making lunch or doing some workouts while letting the computer to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = []\n",
    "for npts in range(100000, 1000001, 100000):\n",
    "    for w in [25, 50, 100, 200, 400, 600, 800]:\n",
    "        x = test_rect_find(w, w, npts=npts)\n",
    "        x = npts, w, x[0], x[1]\n",
    "        results.append(x)\n",
    "\n",
    "for r in results:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note there is a reason the above code is used to printout the tedious results. One of the questions for this module asks for a program that can be used to compute the total time of the above experiment based on the above output. This will be the total time used on the computer to produce this tutorial and it will be an interesting point to see how each of our own computer fares with this NUC 10.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Question 1</font>\n",
    "\n",
    "The above code does not report the total time. We can probably go back and re-run the code to get the total time, but we will have to wait another round. Luckily, we did print out the time returned by the `test_rect_find` function, which tell us the average time for each query. The printout is formatted in a specific way and we can definitely utilize that to get the total time. \n",
    "\n",
    "The goal here is to compute the total time used in the above experiment. You should not redo the experiment. Instead, use the results printed. For example, the first two lines of the results may look like this:\n",
    "\n",
    "```\n",
    "(100000, 25, 0.00013082027435302735, 0.015203642845153808)\n",
    "(100000, 50, 0.0003963470458984375, 0.015846920013427735)\n",
    "```\n",
    "\n",
    "and we can simply add a comma at the end of every line (except the last) and then put it in a pair of brackets. We then assign it to a variable:\n",
    "\n",
    "```\n",
    "myresults = [ \n",
    "(100000, 25, 0.00013082027435302735, 0.015203642845153808),\n",
    "(100000, 50, 0.0003963470458984375, 0.015846920013427735)\n",
    "]\n",
    "```\n",
    "\n",
    "This will create a valid Python data structure that allows us to do necessary calculation. Please also note that the time reported here is the average time per query, so it is important to account for the number of runs when computing the total time. You will need to examine the original code to see how the average is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#\n",
    "#    Double click on this cell and write your code to answer the above question\n",
    "#    In the end, the total time should be printed out.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, at this point, we have a lot of data in `results` to visualize. Here we show the dominating trends in the data using a subset of the results. More specifically, we want to draw a series of 10 plots in a row where each corresponds to one of the 10 sizes (from 100 K to 1 million). On each plot, the horizontal axis is the width of rectangle (from 25 to 800) and the vertical is the time. To do so, we need to reorganize the data in `results` into a dictionary where the keys are the data sizes, and each key is associated with a list of three values: width in hundreds, time for k-D tree, and time for linear search. We initialize the dictionary using a dictionary comprehension with empty lists and then append the corresponding values from `results` using a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {w: [[], [], []] for w in range(100000, 1000001, 100000)}\n",
    "\n",
    "# Can also be done using the following:\n",
    "# new_data = {}\n",
    "# sizes = range(100000, 1000001, 100000)\n",
    "# for w in sizes:\n",
    "#     new_data[w] = [[], [], []]    \n",
    "\n",
    "for r in results:\n",
    "    w = r[0]\n",
    "    new_data[w][0].append(r[1]/100) # width in hundreds\n",
    "    new_data[w][1].append(r[2])\n",
    "    new_data[w][2].append(r[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = list(new_data.keys())\n",
    "\n",
    "panel_label_y = 1.1 * max(new_data[sizes[-1]][1]) # get Y position of panel labels\n",
    "\n",
    "_, axs = plt.subplots(1, len(sizes), sharey=True)\n",
    "\n",
    "for i in range(len(sizes)):\n",
    "    w = sizes[i]\n",
    "    axs[i].plot(new_data[w][0], new_data[w][1], color='grey', label='k-D tree')\n",
    "    axs[i].plot(new_data[w][0], new_data[w][2], color='r', label='Linear')\n",
    "    #plt.xticks([sizes[j]/100 for j in range(len(sizes)) if j%3==0])\n",
    "    axs[i].xaxis.set_ticks([2, 4, 6, 8])\n",
    "    axs[i].text(0.5, panel_label_y, f'{w//1000}K')\n",
    "    i += 1\n",
    "    \n",
    "axs[5].set_xlabel('Width of rectangle (x100)')\n",
    "axs[0].set_ylabel('Search time (Seconds)')\n",
    "plt.legend(loc='right', bbox_to_anchor=(4.5, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Performance of nearest neighbor search\n",
    "\n",
    "Now we test the performance of nearest neighbor search using three methods: k-D tree, point quadtree, and linear search (`nn_linear`). Here are some necessary functions for the testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nn_linear(p, points, n_neighbor=10):\n",
    "    '''Linear search, or exhaustive search, or brute-force search'''\n",
    "    dist = [p.distance(z) for z in points]\n",
    "    Z1 = [(points[i], dist[i]) for i in range(len(dist))]\n",
    "    Z1.sort(key=lambda Z1: Z1[1])\n",
    "    Z1 = Z1[:n_neighbor]\n",
    "    return Z1\n",
    "\n",
    "def test_nn_find(rect=[[10,1000], [10,1000]], n_neighbor=10, npts=100, n_query=10):\n",
    "    randpoints0 = [rand_point(rect) for i in range(npts)]\n",
    "    randpoints = copy.deepcopy(randpoints0)\n",
    "    pqt = pointquadtree(randpoints0)\n",
    "    kdt = kdtree2(randpoints0)\n",
    "\n",
    "    times = []\n",
    "    for i in range(n_query):\n",
    "        p = rand_point(rect)\n",
    "        t1 = time.time()\n",
    "        nnp1 = kdtree_nearest_neighbor_query(kdt, p, n_neighbor)\n",
    "        t2 = time.time()\n",
    "        nnp2 = pq_nearest_neighbor_query(pqt, p, n_neighbor)\n",
    "        t3 = time.time()\n",
    "        nnp3 = nn_linear(p, randpoints, n_neighbor)\n",
    "        t4 = time.time()\n",
    "        times.append((t2-t1, t3-t2, t4-t3))\n",
    "    return sum([t[0] for t in times])/n_query, sum([t[1] for t in times])/n_query, sum([t[2] for t in times])/n_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nn_find(n_neighbor=25, npts=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test a few configurations. We search for up to 800 nearest points (note this is not the same as 800 in the previous experiment where 800 is the width of the rectangle). In our tests below, 800 points is really a small portion of all points. More on this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results_nn = []\n",
    "for npts in range(200000, 1000001, 200000):\n",
    "    for n in [25, 50, 100, 200, 400, 800]:\n",
    "        x = test_nn_find(n_neighbor=n, npts=npts)\n",
    "        x = npts, n, x[0], x[1], x[2]\n",
    "        results_nn.append(x)\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Question 2</font>\n",
    "\n",
    "Plot a figure that can show the time complexity trend of nearest neighbor search using a tree (a k-D tree, a point quadtree, or both) from the above experiment. Again, we don't need to re-run the code. Instead, use the results printed above, where the first two lines of the printout look like this:\n",
    "\n",
    "```\n",
    "(200000, 25, 0.0004232645034790039, 0.0017875194549560546, 0.3703118324279785),\n",
    "(200000, 50, 0.0008641958236694336, 0.0032688140869140624, 0.37016251087188723)\n",
    "```\n",
    "\n",
    "We did not discuss nearest neighbor search the class in this semester, but the algorithms are similar to those of orthogonal and circular searches. Please refer to Sections 5.1.3 and 6.2 of *GIS Algorithms* for more detailed discussions about nearest neighbor search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#\n",
    "#    Double click on this cell and write your code to answer the above question.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, finding 800 nearest neighbors of a point on a tree of 900,000 points is a piece of cake! However, before we can be more conclusive, there are more tests to do: what is the downside of using a k-D tree? We know that constructing such a tree takes time, and from the previous experiments, we also know that at some point the use of a k-D tree for searching may be excessive because we will have to traverse the tree back and forth too many times that will be more than just using a linear search. Does this happen to the nearest neighbor search using k-D tree too? Here are some quick tests and these should give us some good ideas about the last point!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_nn_find(n_neighbor=10, npts=100000))\n",
    "print(test_nn_find(n_neighbor=25, npts=100000))\n",
    "print(test_nn_find(n_neighbor=10000, npts=100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Question 3</font>\n",
    "\n",
    "In the output of the above code we should see something like this in each line:\n",
    "\n",
    "```\n",
    "(11.019792795181274, 29.53496918678284, 0.2186837911605835)\n",
    "```\n",
    "\n",
    "What does each of these three numbers mean? What can we learn from this result? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#\n",
    "#    Double click on this cell and answer the above question here.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do more tests on a smaller tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(test_nn_find(n_neighbor=10, npts=250))\n",
    "print(test_nn_find(n_neighbor=50, npts=250))\n",
    "print(test_nn_find(n_neighbor=100, npts=250))\n",
    "print(test_nn_find(n_neighbor=200, npts=250))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
