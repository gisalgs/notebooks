{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/gisalgs/notebooks/blob/main/computational_issues-colab.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# Computational Issues of Spatial Indexing\n",
    "\n",
    "November 26, 2024\n",
    "\n",
    ">\"How long does getting thin take?\" asked Pooh anxiously.  \n",
    ">\"About a week, I should think.\"  \n",
    ">\"But I can't stay here for a *week*!\"  \n",
    ">\"You can *stay* all right, silly old Bear. It's getting you out which is so difficult.\"\n",
    ">\n",
    "><cite>A. A. Milne, Winnie-the-Pooh</cite>\n",
    "\n",
    ">\"And is all this common consciousness satisfied to use me as a black box? Since the black box works, is it unimportant to know what is inside? --- That doesn't suit me. I don't enjoy being a black box. I want to know what's inside.\"\n",
    ">\n",
    "><cite>Issac Asimov, Foundation and Earth</cite>\n",
    "\n",
    "\n",
    "The computational time for trees can be broken down to at least two parts. The first is the time used to construct the tree, and then it is the time the tree is used to query. The overall time complexity of building a balanced k-D tree is $O(n \\log_2 n)$. Searching a k-D only takes $O(\\log_2 n)$ time in average when the tree is balanced. For unbalanced trees, however, we can imagine a worst case where points are always aligned on one branch of the node and in this case the search time is $O(n)$, as same as the linear search (though the actual time might be longer because traversing a tree takes more time than traversing a list or an array).\n",
    "\n",
    "For point quadtrees, the cost of building a point quadtree is $O(n \\log_4 n)$ when points are randomly sorted before they are inserted to the tree as we discussed above. A simple search on a balanced point quadtree has a time complexity of $O(\\log_4 n)$ while the worst case would be $O(n)$ when the tree has only one node at each depth.\n",
    "\n",
    "The above discussion, however, is theoretical. In practice, the actual computational time may follow the overall trend as predicted, but there are also many other factors that have significant impacts on the performance. For example, the physical time used can vary a lot depending on whether the program is compiled into binary code (as C/C++ programs) or interpreted (as Python and Java). Generally speaking, interpreted programming languages such as Python are less efficient in terms of the actual running time because the code must be interpreted line by line. It should be noted that Python or Java is not the interpreted language in its original meaning where the interpreter literally goes through line by line for every time it runs the program. Instead, they often use an immediate representation of the code that is compiled in binary that runs faster. Still, interpreted languages are still generally slower than compiled languages such as C/C++. The difference may not be noticeable for small data (and probably we don't really care), but the difference will be big when we deal with large data sets. \n",
    "\n",
    "Aside from the programming language, how the algorithms are actually implemented will be a factor too. For example, the use of recursive functions, as convenient as it is, slows down the algorithm because of the repeated recursive function calls. \n",
    "\n",
    "The following are some commands that can be used in the notebook to get info about the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux, Max, or Colab\n",
    "!uname -a\n",
    "print()\n",
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows\n",
    "# !wmic cpu get caption, deviceid, name, numberofcores, maxclockspeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we can check the version of Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Performance of query using k-D trees and point quadtrees\n",
    "\n",
    "Here, we put our algorithms of k-D trees and point quadtrees into a test. We will simply compare the performance of using these trees, and we also compare them with the linear (brute-force) search approach. We test the performance by systematically controlling the size of the data and see how they catch up. The following are the packages that we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following if needed in Jupyter notebook to clone the github repos\n",
    "# !git clone https://github.com/gisalgs/geom.git\n",
    "# !git clone https://github.com/gisalgs/indexing.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geom.point import *\n",
    "from indexing.kdtree1 import *\n",
    "from indexing.kdtree2a import *\n",
    "from indexing.kdtree3 import *\n",
    "from indexing.pointquadtree1 import *\n",
    "from indexing.pointquadtree3 import *\n",
    "\n",
    "from random import random, sample, uniform\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we write a function to do the testing. This function requires inputs of the number of points to be indexed in a tree, the number of points to be queried, and a boolean variable to specify if we need verbose (wordy) output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def test(npts, n, verbose=False):\n",
    "    points = [Point(random(), random()) for i in range(npts)]\n",
    "    time1 = time.time()\n",
    "    kdt1 = kdtree(points)\n",
    "    time2 = time.time()\n",
    "    treet1 = time2-time1\n",
    "    time1 = time.time()\n",
    "    kdt2 = kdtree2(points)\n",
    "    time2 = time.time()\n",
    "    treet2 = time2-time1\n",
    "    time1 = time.time()\n",
    "    kdt3 = pointquadtree(points)\n",
    "    time2 = time.time()\n",
    "    treet3 = time2-time1\n",
    "    \n",
    "    t1 = 0 # time finding n points in kdtree\n",
    "    t2 = 0 # time for balanced kdtree\n",
    "    t3 = 0 # time for point quadtree\n",
    "    t4 = 0 # time for linear search\n",
    "    pp = sample(points, n)\n",
    "    for p in pp:\n",
    "        time1 = time.time()\n",
    "        p1 = query_kdtree(kdt1, p)\n",
    "        time2 = time.time()\n",
    "        t1 = t1 + time2-time1\n",
    "\n",
    "        time1 = time.time()\n",
    "        p1 = query_kdtree(kdt2, p)\n",
    "        time2 = time.time()\n",
    "        t2 = t2 + time2-time1\n",
    "\n",
    "        time1 = time.time()\n",
    "        p1 = search_pqtree(kdt3, p)\n",
    "        time2 = time.time()\n",
    "        t3 = t3 + time2-time1\n",
    "\n",
    "        time1 = time.time()\n",
    "        for i in range(len(points)):\n",
    "            if p == points[i]:\n",
    "                break\n",
    "        time2 = time.time()\n",
    "        t4 = t4 + time2-time1\n",
    "\n",
    "    if verbose:\n",
    "        print(\"{0:7} | {1:6.3f} {2:6.3f} {3:6.3f} | {4:6.3f} {5:6.3f} {6:6.3f} | {7:6.3f}\".format(\n",
    "            npts, treet1, treet2, treet3, t1, t2, t3, t4))\n",
    "    return npts, treet1, treet2, treet3, t1, t2, t3, t4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a quick demo of this function in searching for 100 random points from 10,000 points. The test() function has an input called verbose which can be used to make the function run silently without printing anything. But printing out the current result can be a good feature if we want to know how the program progresses during time (for a long wait)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t1 = test(10000, 100, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above quick test clearly shows the efficiency of using the indexing method for query. It also shows that building the tree may need some significant amount of time. \n",
    "\n",
    "Now we give it a more systematical test. More specifically, we use different numbers of points, ranging from 100,000 to **1,000,000**, with a step of 100,000. All the experiments were done on Now we give it a more systematical test. More specifically, we use different numbers of points, ranging from 100,000 to **1,000,000**, with a step of 100,000. The experiments will be done on different systems (local or cloud) and the numbers will be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "time1 = time.time()\n",
    "n = 100\n",
    "alltime = []\n",
    "for npts in range(100000, 1000001, 100000):\n",
    "    alltime.append(test(npts, n, True))\n",
    "time2=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code reports some numbers, including the total time in minutes and the time used on tree, where almost all of that time are used to construct the tree (so using the tree doesn't take much time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = (time2-time1)/60\n",
    "t2 = sum([sum(alltime[i][1:]) for i in range(len(alltime))])/60\n",
    "t3 = sum([sum(alltime[i][1:7]) for i in range(len(alltime))])/60\n",
    "t4 = sum([sum(alltime[i][1:4]) for i in range(len(alltime))])/60\n",
    "print('total computing time: {:.1f} minutes'.format(t1))\n",
    "print('Total processing time: {:.1f} minutes'.format(t2))\n",
    "print('Total time on trees: {:.1f} minutes'.format(t3))\n",
    "print('Tree construction time: {:.1f} minutes'.format(t4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a way of comparison, the following shows previous results on different platforms.\n",
    "\n",
    "Apple Macbook Air M2, running Python 3.12 in Jupyter notebook on Sonoma 14.0:\n",
    "\n",
    "```\n",
    " 100000 |  0.532  0.311  0.400 |  0.001  0.000  0.001 |  0.357\n",
    " 200000 |  1.256  0.705  1.149 |  0.001  0.001  0.001 |  1.279\n",
    " 300000 |  2.005  1.132  1.913 |  0.001  0.001  0.001 |  2.359\n",
    " 400000 |  2.847  1.492  2.653 |  0.001  0.001  0.001 |  3.366\n",
    " 500000 |  3.609  2.171  3.722 |  0.001  0.001  0.002 |  4.934\n",
    " 600000 |  4.260  2.566  4.417 |  0.001  0.001  0.001 |  6.292\n",
    " 700000 |  5.412  2.888  5.721 |  0.002  0.001  0.002 |  5.814\n",
    " 800000 |  6.151  3.757  6.402 |  0.002  0.001  0.002 |  6.739\n",
    " 900000 |  7.304  3.993  7.982 |  0.002  0.001  0.002 |  8.978\n",
    "1000000 |  7.990  4.825  8.427 |  0.002  0.001  0.002 | 10.055\n",
    "```\n",
    "\n",
    "(total computing time 2.7 minutes, Total processing time 2.6 minutes, Total time on trees 1.8 minutes, Tree construction time 1.8 minutes)\n",
    "\n",
    "Intel Next Computing Unit (NUC) 10, released in 2020, with Intel Core i7-10710U CPU 1.10GHz and 16 GB RAM, running Python 3.13 in Jupyter notebook on Fedora Linux 41 (Workstation Edition), as of November 26, 2024:\n",
    "\n",
    "```\n",
    " 100000 |  1.105  0.511  1.043 |  0.003  0.002  0.002 |  2.010\n",
    " 200000 |  2.591  1.665  2.398 |  0.002  0.002  0.002 |  3.688\n",
    " 300000 |  3.894  2.303  3.812 |  0.003  0.002  0.002 |  5.779\n",
    " 400000 |  5.595  3.233  5.448 |  0.003  0.002  0.002 |  7.805\n",
    " 500000 |  6.996  4.230  7.070 |  0.003  0.002  0.002 | 11.050\n",
    " 600000 |  9.117  5.758  8.027 |  0.003  0.002  0.002 | 12.730\n",
    " 700000 | 10.579  6.481 10.364 |  0.003  0.002  0.002 | 14.667\n",
    " 800000 | 12.317  7.555 11.235 |  0.003  0.002  0.002 | 16.173\n",
    " 900000 | 14.985  8.695 13.759 |  0.003  0.002  0.003 | 19.574\n",
    "1000000 | 16.098 10.597 14.199 |  0.003  0.002  0.002 | 20.015\n",
    "```\n",
    "\n",
    "The same Intel Next Computing Unit, running Python 3.12 in Jupyter notebook on Fedora Linux 39 (Workstation Edition):\n",
    "\n",
    "```\n",
    " 100000 |  1.394  0.658  1.144 |  0.002  0.001  0.002 |  1.520\n",
    " 200000 |  2.987  1.643  2.712 |  0.003  0.002  0.002 |  4.504\n",
    " 300000 |  4.700  2.528  4.260 |  0.003  0.002  0.003 |  7.331\n",
    " 400000 |  6.576  3.942  6.142 |  0.003  0.002  0.003 |  9.911\n",
    " 500000 |  8.363  5.093  8.054 |  0.003  0.002  0.003 | 13.741\n",
    " 600000 | 10.666  6.413 10.017 |  0.003  0.002  0.003 | 16.353\n",
    " 700000 | 12.510  7.072 12.456 |  0.003  0.002  0.003 | 19.033\n",
    " 800000 | 14.909  9.067 14.350 |  0.004  0.002  0.003 | 21.850\n",
    " 900000 | 16.668 10.313 15.352 |  0.004  0.002  0.003 | 23.592\n",
    "1000000 | 18.990 10.767 18.590 |  0.004  0.002  0.003 | 25.214\n",
    "```\n",
    "\n",
    "On the same hardware ((NUC 10), running Python 3.10 in Jupyter notebook on Ubuntu Linux 20.04 LTS:\n",
    "\n",
    "```\n",
    " 100000 |  1.920  0.828  2.066 |  0.005  0.003  0.004 |  2.368\n",
    " 200000 |  4.247  1.914  3.836 |  0.005  0.003  0.003 |  5.215\n",
    " 300000 |  6.216  3.260  6.228 |  0.005  0.003  0.004 |  8.613\n",
    " 400000 |  8.719  4.391  9.310 |  0.006  0.003  0.004 | 12.813\n",
    " 500000 | 11.204  5.569 11.880 |  0.005  0.003  0.004 | 14.315\n",
    " 600000 | 14.169  6.801 14.790 |  0.005  0.003  0.004 | 18.673\n",
    " 700000 | 16.430  8.005 17.451 |  0.006  0.003  0.004 | 19.009\n",
    " 800000 | 19.018  9.822 18.863 |  0.006  0.003  0.004 | 24.452\n",
    " 900000 | 22.156 11.036 23.006 |  0.006  0.003  0.004 | 26.543\n",
    "1000000 | 24.699 12.680 24.078 |  0.006  0.003  0.004 | 28.464\n",
    "```\n",
    "\n",
    "Surface Pro 6 with 2.11 GHz Intel Core i7 and 8 GB RAM, using the Jupyter notebook on Windows 10:\n",
    "\n",
    "```\n",
    " 100000 |  2.594  1.091  2.524 |  0.000  0.000  0.016 |  3.250\n",
    " 200000 |  6.809  2.719  5.968 |  0.000  0.000  0.000 |  8.220\n",
    " 300000 | 12.339  4.629  8.893 |  0.001  0.001  0.000 | 10.954\n",
    " 400000 | 15.386  5.906 12.799 |  0.047  0.001  0.000 | 15.611\n",
    " 500000 | 19.815  7.579 16.616 |  0.016  0.000  0.016 | 18.221\n",
    " 600000 | 24.587 10.533 21.079 |  0.016  0.000  0.000 | 23.317\n",
    " 700000 | 29.092 12.926 24.468 |  0.001  0.000  0.000 | 24.379\n",
    " 800000 | 28.180 12.628 21.286 |  0.000  0.001  0.000 | 26.054\n",
    " 900000 | 30.781 14.205 26.176 |  0.000  0.000  0.017 | 31.078\n",
    "1000000 | 34.803 16.431 29.153 |  0.000  0.001  0.016 | 34.575\n",
    "```\n",
    "\n",
    "\n",
    "Mid 2014 MacBook Pro with 2.6 GHz Intel Core i5 and 8 GB RAM:\n",
    "\n",
    "```\n",
    " 100000 |  3.508  1.600  4.014 |  0.008  0.004  0.005 |  3.660\n",
    " 200000 |  8.407  2.853  7.150 |  0.006  0.004  0.005 |  7.057\n",
    " 300000 | 11.624  4.477 10.934 |  0.006  0.004  0.005 |  9.613\n",
    " 400000 | 16.723  6.327 15.328 |  0.007  0.004  0.005 | 13.463\n",
    " 500000 | 22.370  8.158 18.752 |  0.007  0.004  0.005 | 17.582\n",
    " 600000 | 26.293 10.046 23.697 |  0.007  0.004  0.005 | 20.960\n",
    " 700000 | 30.832 12.099 28.383 |  0.008  0.004  0.006 | 24.593\n",
    " 800000 | 37.189 14.227 32.229 |  0.008  0.004  0.005 | 27.305\n",
    " 900000 | 40.909 16.261 34.749 |  0.008  0.004  0.005 | 35.873\n",
    "1000000 | 46.114 19.159 41.113 |  0.008  0.004  0.006 | 35.620\n",
    "```\n",
    "\n",
    "Let's compare the running on Google Colab in different settings. This is the most recent run on November 26, 2024 where the CPU is Intel(R) Xeon(R) CPU @ 2.20GHz\n",
    "on Python 3.10.12:\n",
    "\n",
    "```\n",
    " 100000 |  2.980  1.361  2.561 |  0.007  0.003  0.005 |  3.801\n",
    " 200000 |  6.925  3.419  6.632 |  0.007  0.003  0.004 |  6.454\n",
    " 300000 | 11.023  5.856 10.438 |  0.007  0.004  0.005 | 10.545\n",
    " 400000 | 16.112  7.568 15.027 |  0.007  0.004  0.005 | 14.083\n",
    " 500000 | 21.305 10.493 17.540 |  0.008  0.004  0.005 | 17.092\n",
    " 600000 | 25.216 11.802 23.009 |  0.008  0.004  0.005 | 19.816\n",
    " 700000 | 31.459 13.691 27.213 |  0.008  0.004  0.005 | 24.672\n",
    " 800000 | 36.653 16.216 33.170 |  0.008  0.004  0.005 | 26.898\n",
    " 900000 | 41.014 18.760 35.908 |  0.008  0.004  0.005 | 34.367\n",
    "1000000 | 46.756 21.700 40.825 |  0.008  0.004  0.005 | 35.964\n",
    "```\n",
    "\n",
    "The following was on November 27, 2021 using Google Colab (Intel(R) Xeon(R) CPU @ 2.20GHz) on an un-recorded Python version but should be 3.8 or 3.9 as shown in [https://devguide.python.org/versions/](https://devguide.python.org/versions/):\n",
    "\n",
    "```\n",
    " 100000 |  3.867  1.145  3.501 |  0.006  0.003  0.005 |  3.912\n",
    " 200000 |  8.256  3.245  7.641 |  0.007  0.004  0.006 |  7.865\n",
    " 300000 | 12.502  4.615 11.573 |  0.007  0.004  0.005 | 12.012\n",
    " 400000 | 17.683  6.418 16.296 |  0.008  0.004  0.006 | 15.480\n",
    " 500000 | 22.426  8.707 20.957 |  0.008  0.004  0.006 | 19.006\n",
    " 600000 | 27.913 10.976 27.320 |  0.008  0.004  0.006 | 22.747\n",
    " 700000 | 32.356 13.120 32.044 |  0.008  0.004  0.006 | 28.663\n",
    " 800000 | 38.028 15.000 35.784 |  0.008  0.004  0.006 | 31.729\n",
    " 900000 | 44.369 16.787 41.919 |  0.008  0.004  0.006 | 34.442\n",
    "1000000 | 47.876 19.579 45.709 |  0.008  0.004  0.006 | 40.508\n",
    "```\n",
    "\n",
    "Finally, the following is done on a MacBook Air (2013) with 1.30 GHz Intel Core i5. But this is on a Linux distro called Ubuntu 21.10. The experiments were conducted on December 8, 2022 using Jupyter notebook with Python 3.9.7.\n",
    "\n",
    "```\n",
    " 100000 |  2.831  1.213  2.682 |  0.006  0.003  0.004 |  2.568\n",
    " 200000 |  6.480  2.793  5.579 |  0.005  0.003  0.004 |  5.152\n",
    " 300000 | 10.367  4.507  9.609 |  0.006  0.003  0.004 |  8.077\n",
    " 400000 | 13.689  6.374 18.599 |  0.009  0.005  0.007 | 17.443\n",
    " 500000 | 19.350  7.430 16.970 |  0.007  0.004  0.005 | 15.099\n",
    " 600000 | 24.454 12.923 31.373 |  0.008  0.004  0.006 | 21.950\n",
    " 700000 | 30.491 11.816 25.521 |  0.006  0.003  0.005 | 19.822\n",
    " 800000 | 31.134 14.268 29.183 |  0.006  0.004  0.005 | 25.155\n",
    " 900000 | 35.490 16.478 30.769 |  0.006  0.003  0.005 | 23.973\n",
    "1000000 | 38.142 18.879 33.845 |  0.007  0.003  0.004 | 27.126\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plot the results for a better visualization of the difference in the performances. Here is a shot at the construction times used for different kinds of trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [ alltime[i][0]/1000 for i in range(len(alltime))]\n",
    "plt.plot(x, [ alltime[i][1] for i in range(len(alltime))], label='k-D tree')\n",
    "plt.plot(x, [ alltime[i][3] for i in range(len(alltime))], label = 'point quadtree')\n",
    "plt.plot(x, [ alltime[i][2] for i in range(len(alltime))], label='k-D tree (balanced)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Number of points (x1000)')\n",
    "plt.ylabel('Seconds')\n",
    "plt.title('Time for tree construction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benefit of using the tree for query is obvious:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, [ alltime[i][7] for i in range(len(alltime))], label='linear')\n",
    "plt.plot(x, [ alltime[i][4] for i in range(len(alltime))], label='k-D tree')\n",
    "plt.plot(x, [ alltime[i][6] for i in range(len(alltime))], label='point quadtree')\n",
    "plt.plot(x, [ alltime[i][5] for i in range(len(alltime))], label='k-D tree (balanced)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Number of points (x1000)')\n",
    "plt.ylabel('Seconds')\n",
    "plt.title('Time to query 100 points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trend of using the tree across the three trees is not clear based on the test we just did, but we can still see from below that the balanced k-D tree is clearly positioned at the bottom of the three curves, showing the efficiency of the balanced tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, [ alltime[i][4] for i in range(len(alltime))], label='k-D tree')\n",
    "plt.plot(x, [ alltime[i][6] for i in range(len(alltime))], label='point quadtree')\n",
    "plt.plot(x, [ alltime[i][5] for i in range(len(alltime))], label='k-D tree (balanced)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Number of points (x1000)')\n",
    "plt.ylabel('Seconds')\n",
    "plt.title('Time to query 100 points')\n",
    "plt.legend(loc='right', bbox_to_anchor=(1.45, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Performance of orthogonal range search\n",
    "\n",
    "We first define a few functions to make it convenient for testing different cases.\n",
    "\n",
    "A note on changes: the textbook (*GIS Algorithms*) has the following line to create random points. \n",
    "\n",
    "`randpoints0 = [Point(randrange(xmin, xmax), randrange(ymin, ymax)) for i in range(npts)]`\n",
    "\n",
    "However, `randrange` will only return integers which will likely produce duplicated points. Here we write a new function called `rand_point` that uses `random.uniform` to generate random points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A rectangle is defined as [ [xmin, xmax], [ymin, ymax]]\n",
    "\n",
    "def in_rect(p, rect):\n",
    "    x, y = p.x, p.y\n",
    "    if not (rect[0][0]>x or rect[0][1] < x or rect[1][0]>y or rect[1][1] < y):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def rectangular_linear(points, rect):\n",
    "    l = []\n",
    "    for p in points:\n",
    "        if in_rect(p, rect):\n",
    "            l.append(p)\n",
    "    return l\n",
    "\n",
    "def rand_point(rect):\n",
    "    '''generates a random point within a rect'''\n",
    "    x = uniform(rect[0][0], rect[0][1])\n",
    "    y = uniform(rect[1][0], rect[1][1])\n",
    "    return Point(x, y)\n",
    "\n",
    "def test_rect_find(w=10, h=10, rect=[[10,1000], [10,1000]], npts=100, n_query=10):\n",
    "    \"\"\"\n",
    "    Repeats n_query times, based on npts points.\n",
    "    Points are random in a area with both x and y ranging  from 10 to 1000.\n",
    "\n",
    "    Uses a balanced k-D tree.\n",
    "    Same set of points are used for n_query times.\n",
    "    Each time, find points in a tree of npts points in a rectangle of w wide and h high. \n",
    "    The rectangle does not go out of the range of x and y.\n",
    "    \n",
    "    Returns times of using the k-D tree and linear search, respectively.\n",
    "    The time is averaged per query.\n",
    "    \"\"\"\n",
    "    randpoints0 = [rand_point(rect) for i in range(npts)]\n",
    "    randpoints = copy.deepcopy(randpoints0)\n",
    "    kdt = kdtree2(randpoints0)\n",
    "\n",
    "    times = []\n",
    "    for i in range(n_query):\n",
    "        x1 = uniform(rect[0][0], rect[0][1]-w)\n",
    "        y1 = uniform(rect[1][0], rect[1][1]-h)\n",
    "        rect_target = [ [x1, x1+w], [y1, y1+h] ]\n",
    "        t1 = time.time()\n",
    "        found = []\n",
    "        range_query_orthogonal(kdt, rect_target, found)\n",
    "        t2 = time.time()\n",
    "        found2 = rectangular_linear(randpoints, rect_target) # linear search\n",
    "        t3 = time.time()\n",
    "        times.append( (t2-t1, t3-t2))\n",
    "    return sum([t[0] for t in times])/float(n_query), sum([t[1] for t in times])/n_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of using it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_rect_find(20, 20, npts=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that using a k-D tree will help rectangular query, but the increase of the rectangle size will increase the time used to query. We test two things here:\n",
    "\n",
    "1. when will the additional computation caused by the increase of the rectangle exceed the efficiency of using a k-D tree?\n",
    "2. what is the impact of increasing the problem size (total number of points)?\n",
    "\n",
    "We test the average of time used for each query for each configuration. The following code will take some significant time to run. It will be important to let the computer run, with power plugged in, and do not disturb it with other heavy lifting tasks such as watching movies or even gaming. We will be better off by making lunch or doing some workouts while letting the computer to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = []\n",
    "for npts in range(100000, 1000001, 100000):\n",
    "    for w in [25, 50, 100, 200, 400, 600, 800]:\n",
    "        x = test_rect_find(w, w, npts=npts)\n",
    "        x = npts, w, x[0], x[1]\n",
    "        results.append(x)\n",
    "\n",
    "for r in results:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note there is a reason the above code is used to printout the tedious results. One of the questions for this module asks for a program that can be used to compute the total time of the above experiment based on the above output. This will be the total time used on the computer to produce this tutorial and it will be an interesting point to see how each of our own computer fares with this NUC 10.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Question 1</font>\n",
    "\n",
    "The above code does not report the total time. We can probably go back and re-run the code to get the total time, but we will have to wait another round. Luckily, we did print out the time returned by the `test_rect_find` function, which tell us the average time for each query. The printout is formatted in a specific way and we can definitely utilize that to get the total time. \n",
    "\n",
    "The goal here is to compute the total time used in the above experiment. You should not redo the experiment. Instead, use the results printed. For example, the first two lines of the results may look like this:\n",
    "\n",
    "```\n",
    "(100000, 25, 0.00013082027435302735, 0.015203642845153808)\n",
    "(100000, 50, 0.0003963470458984375, 0.015846920013427735)\n",
    "```\n",
    "\n",
    "and we can simply add a comma at the end of every line (except the last) and then put it in a pair of brackets. We then assign it to a variable:\n",
    "\n",
    "```\n",
    "myresults = [ \n",
    "(100000, 25, 0.00013082027435302735, 0.015203642845153808),\n",
    "(100000, 50, 0.0003963470458984375, 0.015846920013427735)\n",
    "```\n",
    "\n",
    "This will create a valid Python data structure that allows us to do necessary calculation. Please also note that the time reported here is the average time per query, so it is important to account for the number of runs when computing the total time. You will need to examine the original code to see how the average is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#\n",
    "#    Double click on this cell and write your code to answer the above question\n",
    "#    In the end, the total time should be printed out.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, at this point, we have a lot of data in `results` to visualize. Here we show the dominating trends in the data using a subset of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [ r[0]/1000 for r in results if r[1]==25]\n",
    "t100 = [ r[2] for r in results if r[1]==100]\n",
    "t200 = [ r[2] for r in results if r[1]==200]\n",
    "t800 = [ r[2] for r in results if r[1]==800]\n",
    "tl100 = [ r[3] for r in results if r[1]==100]\n",
    "tl200 = [ r[3] for r in results if r[1]==200]\n",
    "tl800 = [ r[3] for r in results if r[1]==800]\n",
    "\n",
    "plt.plot(x, t800, color='k', label='800 k-D tree')\n",
    "plt.plot(x, tl800, color='r', label='800 Linear')\n",
    "plt.plot(x, tl200, color='g', label='200 Linear')\n",
    "plt.plot(x, tl100, color='b', label='100 Linear')\n",
    "plt.plot(x, t200, color='y', label='200 k-D tree')\n",
    "plt.plot(x, t100, color='brown', label='100 k-D tree')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Number of points (x1000)')\n",
    "plt.ylabel('Seconds')\n",
    "plt.title('Search time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, the numbers in the legend refer to the size of the rectangle. We always use a squire in this test and the overall area is a 990x990 box. It appears that a rectangle of 800x800 takes most of the entire area and therefore takes a lot of time to get the points, more than linear search. However, for other rectangle sizes, the use of k-D tree seems to be beneficial. \n",
    "\n",
    "We now examine the result from another perspective: how the size of the rectangle affects performance? We first pull out the results for the data of 1,000,000 points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ttree = []\n",
    "tlinear = []\n",
    "for r in results:\n",
    "    if r[0]==1000000:\n",
    "        xs.append(r[1])\n",
    "        ttree.append(r[2])\n",
    "        tlinear.append(r[3])\n",
    "\n",
    "plt.plot(xs, ttree, color='k', label='k-D tree')\n",
    "plt.plot(xs, tlinear, color='r', label='Linear')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Width of rectangle')\n",
    "plt.ylabel('Search time (Seconds)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above figure is interesting: the use of k-D tree will become more computationally expensive when the size of rectangle is greater than about 500x500. How about other settings? Below, we try to pull all the results and re-organize them into a different structure. More specifically, we use a Python dictionary to organize. We use the data size (number of points) as the key to build the dictionary. For each key, we store three lists: the lists of rectangle sizes, time used by the k-D tree, and by the linear search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {}\n",
    "sizes = range(100000, 1000001, 100000)\n",
    "for w in sizes:\n",
    "    new_data[w] = [[], [], []]    \n",
    "\n",
    "for r in results:\n",
    "    w = r[0]\n",
    "    new_data[w][0].append(r[1]/100)\n",
    "    new_data[w][1].append(r[2])\n",
    "    new_data[w][2].append(r[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the newly organized results (as saved in new_data), we can now put all the lines together in one figure. This is not necessarily the best way to draw things, but a quick way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in sizes:\n",
    "    plt.plot(new_data[w][0], new_data[w][1], color='k', label='k-D tree')\n",
    "    plt.plot(new_data[w][0], new_data[w][2], color='r', label='Linear')\n",
    "\n",
    "#plt.legend(loc='upper left')\n",
    "plt.xlabel('Width of rectangle (x100)')\n",
    "plt.ylabel('Search time (Seconds)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above figure is quick and fun, but not very much useful in reading it. The following illustrate is a remake using the same data and is stunningly effective in showing the intrinsic trends!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numsubplots = len(sizes)\n",
    "\n",
    "_, axs = plt.subplots(1, numsubplots, sharey=True)\n",
    "panel_label_y = 1.1 * max(new_data[sizes[-1]][1]) # get Y position of panel labels\n",
    "\n",
    "i = 0\n",
    "for w in sizes:\n",
    "    axs[i].plot(new_data[w][0], new_data[w][1], color='grey', label='k-D tree')\n",
    "    axs[i].plot(new_data[w][0], new_data[w][2], color='r', label='Linear')\n",
    "    #plt.xticks([sizes[j]/100 for j in range(len(sizes)) if j%3==0])\n",
    "    axs[i].xaxis.set_ticks([2, 4, 6, 8])\n",
    "    axs[i].text(0.5, panel_label_y, f'{w//1000}K')\n",
    "    i += 1\n",
    "    \n",
    "axs[5].set_xlabel('Width of rectangle (x100)')\n",
    "axs[0].set_ylabel('Search time (Seconds)')\n",
    "plt.legend(loc='right', bbox_to_anchor=(4.5, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Performance of nearest neighbor search\n",
    "\n",
    "Now we test the performance of nearest neighbor search using three methods: k-D tree, point quadtree, and linear search (`nn_linear`). Here are some necessary functions for the testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nn_linear(p, points, n_neighbor=10):\n",
    "    '''Linear search, or exhaustive search, or brute-force search'''\n",
    "    dist = [p.distance(z) for z in points]\n",
    "    Z1 = [(points[i], dist[i]) for i in range(len(dist))]\n",
    "    Z1.sort(key=lambda Z1: Z1[1])\n",
    "    Z1 = Z1[:n_neighbor]\n",
    "    return Z1\n",
    "\n",
    "def test_nn_find(rect=[[10,1000], [10,1000]], n_neighbor=10, npts=100, n_query=10):\n",
    "    randpoints0 = [rand_point(rect) for i in range(npts)]\n",
    "    randpoints = copy.deepcopy(randpoints0)\n",
    "    pqt = pointquadtree(randpoints0)\n",
    "    kdt = kdtree2(randpoints0)\n",
    "\n",
    "    times = []\n",
    "    for i in range(n_query):\n",
    "        p = rand_point(rect)\n",
    "        t1 = time.time()\n",
    "        nnp1 = kdtree_nearest_neighbor_query(kdt, p, n_neighbor)\n",
    "        t2 = time.time()\n",
    "        nnp2 = pq_nearest_neighbor_query(pqt, p, n_neighbor)\n",
    "        t3 = time.time()\n",
    "        nnp3 = nn_linear(p, randpoints, n_neighbor)\n",
    "        t4 = time.time()\n",
    "        times.append((t2-t1, t3-t2, t4-t3))\n",
    "    return sum([t[0] for t in times])/n_query, sum([t[1] for t in times])/n_query, sum([t[2] for t in times])/n_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nn_find(n_neighbor=25, npts=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test a few configurations. We search for up to 800 nearest points (note this is not the same as 800 in the previous experiment where 800 is the width of the rectangle). In our tests below, 800 points is really a small portion of all points. More on this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results_nn = []\n",
    "for npts in range(200000, 1000001, 200000):\n",
    "    for n in [25, 50, 100, 200, 400, 800]:\n",
    "        x = test_nn_find(n_neighbor=n, npts=npts)\n",
    "        x = npts, n, x[0], x[1], x[2]\n",
    "        results_nn.append(x)\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Question 2</font>\n",
    "\n",
    "Plot a figure that can show the time complexity trend of nearest neighbor search using a tree (a k-D tree, a point quadtree, or both) from the above experiment. Again, we don't need to re-run the code. Instead, use the results printed above, where the first two lines of the printout look like this:\n",
    "\n",
    "```\n",
    "(200000, 25, 0.0004232645034790039, 0.0017875194549560546, 0.3703118324279785),\n",
    "(200000, 50, 0.0008641958236694336, 0.0032688140869140624, 0.37016251087188723)\n",
    "```\n",
    "\n",
    "We did not discuss nearest neighbor search the class in this semester, but the algorithms are similar to those of orthogonal and circular searches. Please refer to Sections 5.1.3 and 6.2 of *GIS Algorithms* for more detailed discussions about nearest neighbor search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#\n",
    "#    Double click on this cell and write your code to answer the above question.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, finding 800 nearest neighbors of a point on a tree of 900,000 points is a piece of cake! However, before we can be more conclusive, there are more tests to do: what is the downside of using a k-D tree? We know that constructing such a tree takes time, and from the previous experiments, we also know that at some point the use of a k-D tree for searching may be excessive because we will have to traverse the tree back and forth too many times that will be more than just using a linear search. Does this happen to the nearest neighbor search using k-D tree too? Here are some quick tests and these should give us some good ideas about the last point!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_nn_find(n_neighbor=10, npts=100000))\n",
    "print(test_nn_find(n_neighbor=25, npts=100000))\n",
    "print(test_nn_find(n_neighbor=10000, npts=100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Question 3</font>\n",
    "\n",
    "In the output of the above code we should see something like this in each line:\n",
    "\n",
    "```\n",
    "(11.019792795181274, 29.53496918678284, 0.2186837911605835)\n",
    "```\n",
    "\n",
    "What does each of these three numbers mean? What can we learn from this result? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#\n",
    "#    Double click on this cell and answer the above question here.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do more tests on a smaller tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(test_nn_find(n_neighbor=10, npts=250))\n",
    "print(test_nn_find(n_neighbor=50, npts=250))\n",
    "print(test_nn_find(n_neighbor=100, npts=250))\n",
    "print(test_nn_find(n_neighbor=200, npts=250))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
