{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "052ba062-c0f9-42b9-a1c4-29fa4ad59241",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/gisalgs/notebooks/blob/main/POI-point-of-interest-case-study-part1-colab.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# Case Study: Accessibility - Part 1\n",
    "\n",
    "\n",
    "The City of Columbus has put together a collection of points of interest for different functional categories. This data can be viewed at their interactive website https://opendata.columbus.gov/datasets/columbus::points-of-interest/explore. The description of the data can be found at https://maps2.columbus.gov/arcgis/rest/services/Schemas/PointsOfInterest/MapServer/10. The raw geojson file has been posted at https://raw.githubusercontent.com/gisalgs/data/refs/heads/master/columbus_points_of_interest.geojson. We will use this geojson file in this tutorial.\n",
    "\n",
    "The goal of this tutorial is to demonstrate the use of Python for spatial data analysis. More specifically, we will examine how residents in Franklin county can access some of the services represented in this data set. Here, we must realize that the data is incomplete because it may not fully cover areas outside the city of Columbus and some points of interest may not be included in the data either. The main purpose is the demonstrate the use of data and Python coding to analyze accessibility. \n",
    "\n",
    "Most of the code is not directly shown in the original tutorial. The associated video (from the in-class demo) will have a walk-through of most of the processes. After finishing this tutorial, students should answer the following questions (with code):\n",
    "\n",
    "1. How many types of points of interest are represented in the data and how many instances are there in each type?\n",
    "2. Where are the POIs distributed on a map? \n",
    "3. If we redistribute the population of Franklin County evenly into cells in each census block group, who does the population distribution look like on the map?\n",
    "4. How accessibility to a certain service (medical) looks like on the map?\n",
    "5. What are the shortcomings of the analysis presented in this tutorial?\n",
    "\n",
    "\n",
    "## Accessibility: a very short introduction\n",
    "\n",
    "We will use this data to compute the accessibility to various services and we will use health as an example. Accessibility is a big topic and we will focus on a particular approach called the two-step floating catchment area (2SFCA) method (Luo and Wang 2003). Let's assume we want to compute the accessibility at location $i$ to various services provided at locations denoted as $j$. We call $i$ the demand location and $j$ the supply location. The first step is to compute the supply to demand ratio at each supply location $j$ as follows:\n",
    "\n",
    "$R_j = \\Large\\frac{S_j}{\\sum_{k \\in (d_{jk} < d_0)} D_k}$\n",
    "\n",
    "where $R_j$ is the ratio, $S_j$ is the capacity of the supply at location $j$, $d_{kj}$ is the demand from location $k$ that require supply from $j$, and $d_0$ is a distance buffer that defines the catchment of supply $j$. We use $(d_{jk} < d_0)$ to a set of locations ($k$) whose distance to $j$ is smaller than $d_0$. We can replace this set with any set that can be used to define the catchment and therefore the catchment doesn't have to be a circular buffer but can be of any shape. The above equation basically counts all the demand within the catchment (defined by a radius of $d_0$) and split the supply among them. Here, the demand is weighted equally regardless of how far it is from the supply. It is reasonable, as many researchers have done so, to further weight the demand by some kind of  impedance function (e.g., distance decay function). This, however, is dependent on the actual demand and supply. \n",
    "\n",
    "The second step, now that we have worked out the supply side, is to actually compute the accessibility at the demand side by simply add up all the supply to demand ratios that are within the catchment radius of the demand location:\n",
    "\n",
    "$\\Large A_i = \\sum_{j\\in (d_{ij}<d_0)}{R_j}$\n",
    "\n",
    "where $A_i$ is the accessibility at demand $i$ and we use $(d_{ij} < d_0)$ to denote the supply locations ($j$) that are within the distance of $d_0$. \n",
    "\n",
    "In an application, we have many demand locations to calculate and we will \"float\" this calculation over the space so that we get the accessibility measure of all the locations of our interest. \n",
    "\n",
    "**Work cited**\n",
    "\n",
    "Luo, W., & Wang, F. (2003). Measures of spatial accessibility to health care in a GIS environment: synthesis and a case study in the Chicago region. Environment and planning B: planning and design, 30(6), 865-884."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21630c26-0e89-4a09-89e9-3c597e598810",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf geom\n",
    "!git clone https://github.com/gisalgs/geom.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a511f84-724e-43cb-971d-621556333c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as request\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1958fa10-4de1-4446-b1d3-ceeba1dbb7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/gisalgs/data/refs/heads/master/columbus_points_of_interest.geojson'\n",
    "with request.urlopen(url) as response:\n",
    "    poi = json.loads(response.read())\n",
    "\n",
    "len(poi['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcbd76d-93d1-4f9d-a275-e35e74600287",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/gisalgs/data/refs/heads/master/blockgrps_pop_franklin_2.geojson'\n",
    "with request.urlopen(url) as response:\n",
    "    blkgrps = json.loads(response.read())\n",
    "\n",
    "len(blkgrps['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6854c136-744b-468d-99c0-47122f0e1144",
   "metadata": {},
   "outputs": [],
   "source": [
    "blkgrps['features'][0]['properties'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba4e9c4-db58-42ec-9f42-3b62fc104165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many are multiplygons -- all of them!\n",
    "\n",
    "sum([f['geometry']['type'] == 'MultiPolygon' for f in blkgrps['features']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0ffc0f-06e5-4356-9047-27bbb2caa374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many have multiple parts\n",
    "\n",
    "# there are two \n",
    "\n",
    "sum([len(f['geometry']['coordinates'])>1 for f in blkgrps['features']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e785e809-1db4-46db-bd77-61455917c6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# holes?\n",
    "\n",
    "# How many have holes -- forget about the two with multiple parts\n",
    "\n",
    "# there is one\n",
    "\n",
    "sum([len(f['geometry']['coordinates'][0])>1 for f in blkgrps['features']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c121508-3b0c-4043-af73-803b5356fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in blkgrps['features']:\n",
    "    if len(f['geometry']['coordinates'][0])>1:\n",
    "        print(f['properties']['TRACT'], f['properties']['BLKGRP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c304244c-74d3-469c-bc8f-c4fab1e3f55a",
   "metadata": {},
   "source": [
    "Explore the types of geometry in the POI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24510e1-68bb-4b3d-b97f-66feb188e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_types = []\n",
    "for p in poi['features']:\n",
    "    t = p['geometry']['type']\n",
    "    if t not in geom_types:\n",
    "        geom_types.append(t)\n",
    "\n",
    "geom_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074878fc-f775-478c-9449-fe4ee81c1e05",
   "metadata": {},
   "source": [
    "Now we know all the features are of the same type: Point. Let's know explore the attributes a little bit before we draw the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0063a81-2493-47ba-8363-5d92a7c10373",
   "metadata": {},
   "outputs": [],
   "source": [
    "p['properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4306f23-bc6b-4924-bcc8-61e9acd0de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_types = {}\n",
    "for p in poi['features']:\n",
    "    t = p['properties']['POI_TYPE']\n",
    "    if t not in poi_types:\n",
    "        poi_types[t] = 1\n",
    "    else:\n",
    "        poi_types[t] += 1\n",
    "\n",
    "print(poi_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f72c4c-d79c-4823-949f-f7dfd4e54102",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_types_main = {}\n",
    "for t in poi_types:\n",
    "    tt = t.split(' - ')[0]\n",
    "    if tt not in poi_types_main:\n",
    "        poi_types_main[tt] = poi_types[t]\n",
    "    else:\n",
    "        poi_types_main[tt] += poi_types[t]\n",
    "\n",
    "poi_types_main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206af561-fdd8-43e5-9ce7-c2af623b68fb",
   "metadata": {},
   "source": [
    "Something is wrong here. Apparently, some dashes in the key are not the same dashes. We can suspect they are automatically converted from a hyphen symbol from the keyboard to a dash when people typed the values in their computer system (a lot of times doing things in Microsoft Word does this if we don't pay attention). Let's give this a further examination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224df986-e955-443e-bf37-e7f78096c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in 'Retail – Commercial/Retail':\n",
    "    print(ord(c), end=' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcf124c-1dd1-4e87-bed0-bf60818ce868",
   "metadata": {},
   "source": [
    "The `ord` function returns the Unicode of a character. If the code is smaller than 128, then the character is what we call an ascii character, or in plain English, a text. Otherwise, it is a special character that is coded beyond the 8 bit ascii characters. Guess which on is beyond?\n",
    "\n",
    "Guilty as charged!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55610ded-0aab-4b1e-978b-157e4a5fbc59",
   "metadata": {},
   "source": [
    "Now we need to find a way to make sure the dash-like symbol is actually used to split the strings. To get the character, we use the `chr` function in an f-string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae6880e-f124-4e99-9342-cf5b296074fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f' {chr(8211)} '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6a886b-ef73-43d1-8d43-fa0e9991b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Retail – Commercial/Retail'.split(f' {chr(8211)} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac021147-a894-4601-ba96-153b5d35a19a",
   "metadata": {},
   "source": [
    "Now we are going to use multiple delimiters to split strings. Unfortunately, the default method `split` for strings cannot do this and we will have to use something that is bigger than what we need. We are going to use another native Python library called `re`, which is used to handle regular expressions (hence re). This is an extremely complicated topic--people write books about this, one being [here](https://www.amazon.com/Mastering-Regular-Expressions-Jeffrey-Friedl/dp/0596528124/ref=asc_df_0596528124/?tag=hyprod-20&linkCode=df0&hvadid=692875362841&hvpos=&hvnetw=g&hvrand=10753013780408513308&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9014986&hvtargid=pla-2281435177858&psc=1&mcid=86ae5603da983d6b9314bd0e9ed46f65&hvocijid=10753013780408513308-0596528124-&hvexpln=73)--and we will only use one single function in this library. It is also called `split`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2105761f-5031-4206-a65d-c9745c1e5765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "poi_types_main = {}\n",
    "for t in poi_types:\n",
    "    # tt = t.split(' - ')[0]\n",
    "    tt = re.split(f' - | {chr(8211)} ', t)[0]\n",
    "    if tt not in poi_types_main:\n",
    "        poi_types_main[tt] = poi_types[t]\n",
    "    else:\n",
    "        poi_types_main[tt] += poi_types[t]\n",
    "\n",
    "poi_types_main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fda7a8-0eb2-4151-b95e-b6c3302fb341",
   "metadata": {},
   "source": [
    "Now there is only one problem: the two categories called 'Emergency Response' and 'Emergency  Response' should be the same. Again human errors. We will write code to merge them into the right one. We again use a [method in the `re` module called `sub`](https://docs.python.org/3/library/re.html#re.sub). In the following code, the symbol + means a pattern formed by multiple of the string before the symbol, which will be replaced by the second argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1535258-d104-41be-af93-7b9daf87b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(' +', ' ', 'a    b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c05be5a-7d18-450b-b71b-dca09147e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_types_final = {}\n",
    "for t in poi_types_main:\n",
    "    tt = re.sub(' +', ' ', t)\n",
    "    if tt not in poi_types_final:\n",
    "        poi_types_final[tt] = poi_types_main[t]\n",
    "    else:\n",
    "        poi_types_final[tt] += poi_types_main[t]\n",
    "\n",
    "poi_types_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b94544c-38c4-4ec5-ba02-e3536ae8e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f2716-de8c-4fa9-b84d-f783ecff6eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos = range(len(poi_types_final))\n",
    "\n",
    "plt.barh(y_pos, poi_types_final.values(), align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, poi_types_final)\n",
    "plt.xlabel('Count')\n",
    "plt.title('POI Types')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ddf85-203c-49c9-b29d-24fb6e39610b",
   "metadata": {},
   "source": [
    "This is nice but we would like to show the bars ordered. Unfortunately Python doesn't allow us to sort the dictionary. We will have use a list to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8181fcf-1519-4f7f-8e46-d495ebd7c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = [ [t, poi_types_final[t]] for t in poi_types_final]\n",
    "summary.sort(key = lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb54309-2597-48e9-a008-732c3bb5b4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos = range(len(summary))\n",
    "\n",
    "plt.barh(y_pos, [v[1] for v in summary], align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, [v[0] for v in summary])\n",
    "plt.xlabel('Count')\n",
    "plt.title('POI Types')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d94f0f-03c2-4686-b11a-163d1bdca226",
   "metadata": {},
   "source": [
    "## Color\n",
    "\n",
    "Before we go any further, let's talk a little more about color in matplotlib. Eventually we want to map these POIs using their categories, and we have a set of category small enough to make a map (so that we don't have to use too many colors). \n",
    "\n",
    "A typical way to use color for visualization is to define a color ramp (or color map) and we can then map our numerical data range to that color map, and in this way each value will be automatically assigned a color.\n",
    "\n",
    "Matplotlib has a huge set of color maps for different purposes: https://matplotlib.org/stable/users/explain/colors/colormaps.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21910f-d0bf-48dc-9910-38acc3d16bc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import colormaps\n",
    "for c in colormaps:\n",
    "    print(c, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3052b68c-c53f-4fda-9259-6b52abc0fa4b",
   "metadata": {},
   "source": [
    "More specifically, there are colors some colors specifically useful for categorical data. But confusingly, they are in a collection called color_sequences. We should not confuse this name with sequential color. They are merely a sequence of color put together for categorical data. We are going to use the one called `tab20`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7cb8a2-a085-4f65-8552-871b059dbeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import color_sequences\n",
    "for c in color_sequences:\n",
    "    print(c, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aada2ba-0f34-41b7-99ba-21daebdad62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.get_cmap('tab20')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c33f03-2977-4111-b6af-c59482c3baa6",
   "metadata": {},
   "source": [
    "We can now assign a color to each of the types using a dictionary called `poi_types_color`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f62acf0-18b7-40f3-b0e7-118f7332b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = color_sequences['tab20']\n",
    "poi_types_color = {}\n",
    "i = 0\n",
    "for t in poi_types_final:\n",
    "    poi_types_color[t] = cmap[i]\n",
    "    i += 1\n",
    "\n",
    "poi_types_color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ab6e64-85a0-46db-b818-5733b8c92a49",
   "metadata": {},
   "source": [
    "Now we assign each feature in the POI data a color, determined by its type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56520d05-ec95-49fb-8f14-ec28bb193475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the data\n",
    "\n",
    "for f in poi['features']:\n",
    "    f_type = re.split(f' - | {chr(8211)} ', f['properties']['POI_TYPE'])[0]\n",
    "    f_type = re.sub(' +', ' ', f_type)\n",
    "    f['poi_type'] = f_type\n",
    "    f['color'] = poi_types_color[f_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8019af99-67fa-4445-99f6-e644ae0bbb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "for t in poi_types_final:\n",
    "    x = [f['geometry']['coordinates'][0] for f in poi['features'] if f['poi_type']==t]\n",
    "    y = [f['geometry']['coordinates'][1] for f in poi['features'] if f['poi_type']==t]\n",
    "    c = [f['color'] for f in poi['features'] if f['poi_type']==t]\n",
    "    if x:\n",
    "        scatter = plt.scatter(x, y, c=c, label=t, marker='o', alpha=0.5, s=5)\n",
    "\n",
    "ax.set_aspect(1)\n",
    "ax.legend( loc=\"right\", bbox_to_anchor=(1.5, 0.5),)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6fa9c6-e794-4754-ae2f-8d63a9690cf6",
   "metadata": {},
   "source": [
    "Let's just draw a small sample of the points in order to get a clearer picture of things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d256295c-6ad1-45f1-a102-4ebe7f1feaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "some_poi = random.sample(poi['features'], 1000)\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "for t in poi_types_final:\n",
    "    x = [f['geometry']['coordinates'][0] for f in some_poi if f['poi_type']==t]\n",
    "    y = [f['geometry']['coordinates'][1] for f in some_poi if f['poi_type']==t]\n",
    "    c = [f['color'] for f in some_poi if f['poi_type']==t]\n",
    "    if x:\n",
    "        scatter = plt.scatter(x, y, c=c, label=t, marker='o', alpha=0.8)\n",
    "\n",
    "ax.set_aspect(1)\n",
    "ax.legend( loc=\"right\", bbox_to_anchor=(1.5, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49294127-7b63-4818-82b8-c37f1fd4cfbf",
   "metadata": {},
   "source": [
    "## Interpolation: population\n",
    "\n",
    "Before we can calculate accessibility, it is important to get the demand figured out. Here, we will use the total population to represent the demand. More specifically, we will create a raster data set where each cell has a certain size. To do this, let's first set the area to the range of -83.2 to -82.7 longitudes and 39.8 to 40.2 latitudes. This is a rough estimate using the coordinates of the point and we can come back and change it if the area is off. We want a increment of 0.01 degrees. On a great circle or on a meridian, this increment is equivalent to about 0.69 miles or 1.11 km, as shown below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27055a1-6b2c-4f5f-b36b-44f244c48768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\n",
    "radius = 3959 # miles\n",
    "circumference = 2 * pi * radius \n",
    "degreelength = circumference/360\n",
    "degreelength, 0.01*degreelength"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1050d45b-2643-4e6b-85c6-ff245dd625cc",
   "metadata": {},
   "source": [
    "We use the point at the center of the \"cell\" to represent the cell and we first get the coordinates of these centers, as `xs` and `ys` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c8b04-5178-4caf-be71-af52538eb283",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax = -83.2, -82.7\n",
    "ymin, ymax = 39.8, 40.2\n",
    "delta = 0.01\n",
    "\n",
    "xn = int((xmax-xmin)/delta)\n",
    "yn = int((ymax-ymin)/delta)\n",
    "\n",
    "xs = [xmin + i*delta + delta/2 for i in range(xn)] # make sure the point is at the center of the cell of 0.05 degree\n",
    "ys = [ymin + i*delta + delta/2 for i in range(yn)]\n",
    "\n",
    "len(xs), len(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91bc397-0351-47a4-a026-32e68d46fb36",
   "metadata": {},
   "source": [
    "\n",
    "We interpolate the population data in census block groups into the cells. To do so, we go through each cell and check which block group contains the center. After we are done, we split the population to the cells in the block group. \n",
    "\n",
    "But we will have to do this in a \"smart\" way because we don't want to go over the block groups over and over again. To do so, we get the bounds of the polygons and do things from there. This is going to be useful later on and we develop a function for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f0522a-0a4b-476f-9e11-c35876e07516",
   "metadata": {},
   "source": [
    "We are going to use a [specific function that returns the bounds](https://github.com/gisalgs/geom/blob/master/multipolygon_util.py) of a geojson polygon or multipolygon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11305492-d81c-4439-a817-5b0b611d0300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geom.multipolygon_util import get_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab16122-2eac-4d5f-a6c4-e28847f5aaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in blkgrps['features']:\n",
    "    f['bounds'] = get_bounds(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b557b5ca-ae83-4dfb-b700-a9700bec5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "blkgrps['features'][0]['bounds']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16111a65-5746-4d38-96d7-4f1119823686",
   "metadata": {},
   "source": [
    "Now, we interpolate!\n",
    "\n",
    "In addition to the pop_cross function, we also import the function called [`point_in_multipolygon`](https://github.com/gisalgs/geom/blob/master/multipolygon_util.py) to help us get determine a more general case. This will import the pip_cross."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d44ca48-924c-45f1-b903-7447f7104191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geom.point import *\n",
    "from geom.multipolygon_util import point_in_multipolygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b45c34-bdc6-4c91-8b8a-c0268969cb7a",
   "metadata": {},
   "source": [
    "We write a small function that help us determine if a point is outside of a bounding box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aec737-218c-4c88-8100-6c7f4ba7ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_bound(p, b):\n",
    "    '''\n",
    "    p - a Point object\n",
    "    b - bounds [xmin, xmax, ymin, ymax]\n",
    "    '''\n",
    "    return p[0]<b[0] or p[0]>b[1] or p[1]<b[2] or p[1]>b[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23356360-0bbc-47f5-91c6-342a82251221",
   "metadata": {},
   "source": [
    "Now we do a quick interpolation using longitudes and latitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569482a7-06e4-458a-9766-91eec3a0bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = []\n",
    "for y in ys:\n",
    "    for x in xs:\n",
    "        item = {'point': Point(x, y), 'total':0}\n",
    "        p = Point(x, y)\n",
    "        for f in blkgrps['features']:\n",
    "            if not out_bound(p, f['bounds']):\n",
    "                if point_in_multipolygon(p, f):\n",
    "                    item['total'] = f['properties']['Total']\n",
    "                    break\n",
    "        cells.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beb5d2a-db7c-4b9d-80e1-dd55f37c3b13",
   "metadata": {},
   "source": [
    "Now we reorganize the data so that we can display the results. We put the cells in a list of lists where the inner list holds the cells in a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d406ff8a-57c2-46ba-b855-3767ae956a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = [[] for _ in range(len(ys))]\n",
    "for i in range(len(ys)):\n",
    "    totals[len(ys)-i-1] = [c['total'] for c in cells[i*len(xs):(i+1)*len(xs)]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae182d7-2b9d-4f14-bc55-b77893931818",
   "metadata": {},
   "source": [
    "Then we use [plt.imshow](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html) to display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515a97fb-e621-4369-bcd6-2c642da79bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = colormaps.get_cmap('gray_r')\n",
    "plt.imshow(totals, cmap=cmap)\n",
    "plt.colorbar(shrink=0.6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694f999e-dda1-4cb1-a251-c6a81f5f5cd5",
   "metadata": {},
   "source": [
    "## To be continued in part 2\n",
    "\n",
    "The coordinates in the above plot seem strange because they are not lat/lon or anything we are familiar with. Do we get everything right? There are two things we need to check before we continue. First, are the ranges correctly cover the county? If not we need to adjust and **redo** the above interpolation. Hint: The ranges should be -83.3 to -82.7 longitudes and 39.6 to 40.2 latitudes.\n",
    "\n",
    "Second, are we sure we got the geography right? To check that we need to put the county outline on top of the cells and visually confirm. To address this, we will make sure the extent of the plot reflects the coordinates we actually use, and we also want to overlay the county outline to visually confirm. Here is the county outline, another geojson file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c26d21d-a812-4bc6-a942-483a1884b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/gisalgs/data/refs/heads/master/dissolved_blkgrps.geojson'\n",
    "with request.urlopen(url) as response:\n",
    "    franklin = json.loads(response.read())\n",
    "\n",
    "len(franklin['features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f81320-f78b-465f-ba8b-49526a744ace",
   "metadata": {},
   "source": [
    "Then here is the overlay. (We need to make sure the extent is correct.)\n",
    "\n",
    "We will force the mapping of the image (i.e., cells) to an extent that defined previously with xmin, xmax, etc. However, to perfectly map the cells, we should know that the cells do not fully fit in the entire extent, from xmin to xmax. Instead, there is a little left on the right side and at the top. So the actual extent is this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a577804-714c-4858-addb-f2c65b48b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = [xmin, xmin+xn*delta, ymin, ymin+yn*delta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b8320-b807-43c9-9bd9-8a07f4a6c786",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "cmap = colormaps.get_cmap('gray_r')\n",
    "plt.imshow(totals, extent=extent, cmap=cmap)\n",
    "plt.colorbar(shrink=0.6)\n",
    "\n",
    "p1 = plt.Polygon(franklin['features'][0]['geometry']['coordinates'][0][0], closed=True, fill=False, edgecolor='blue', alpha=0.5)\n",
    "ax.add_patch(p1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f03222-09d2-42ad-a959-d888cad08c9d",
   "metadata": {},
   "source": [
    "We should expect a \"perfect\" fit!\n",
    "\n",
    "In sum, the next will involve the following steps:\n",
    "\n",
    "1. Convert all coordinates to the Ohio South State Plane Coordinate System using the function `spcs_ohio_south` from the [lcc](https://github.com/gisalgs/geom/blob/master/lcc.py) module in geom.\n",
    "2. Recalculate the population for a new set of cells using the new coordinates.\n",
    "3. Calculate accessibility for each cell to education services.\n",
    "4. Draw a lot of maps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39299231-b07a-472e-8a42-503a16149ab2",
   "metadata": {},
   "source": [
    "First, we project the block groups and the county outline. To make things simple, we use a function called `proj_multipoly` in the same multipolygon_util module along with the other functions have have used so far (`get_bounds` and `point_in_multipolygon`). This function requires another function to do the actual projection. In our particular case, we are going to use the Ohio South State Plane Coordinate System, which is implemented in the `lcc` module (also in geom and github) and can be imported as follows:\n",
    "\n",
    "```python\n",
    "from geom.lcc import spcs_ohio_south\n",
    "```\n",
    "\n",
    "The conversion function simply copies everything but the coordinates, which will be converted using the `spcs_ohio_south` function as imported here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb1c25c-1bf3-4a2f-8332-d303092086a9",
   "metadata": {},
   "source": [
    "In our actual implementation of the two-step floating catchment area, we use an \"enhanced\" version (Luo and Qi 2009) by applying a distance-decay weights in both steps. In short, we have \n",
    "\n",
    "$R_j = \\Large\\frac{S_j}{\\sum_{k \\in (d_{jk} < d_0)} D_k e^{-(\\beta d_{jk})^2}}$\n",
    "\n",
    "where $e^{-(\\beta d_{jk})^2}$ is a general form of a [Gaussian function](https://en.wikipedia.org/wiki/Gaussian_function) and $\\beta$ is a parameter. We will see how the use of the parameter changes the result and how to choose one. We also apply weight to the calculation of accessibility\n",
    "\n",
    "$\\Large A_i = \\sum_{j\\in (d_{ij}<d_0)}{R_j e^{-(\\beta d_{ij})^2}}$\n",
    "\n",
    "The original 2SFCA method is a special case of the enhanced one, which is called E2SFCA.\n",
    "Work cited:\n",
    "\n",
    "Luo, W., & Qi, Y. (2009). An enhanced two-step floating catchment area (E2SFCA) method for measuring spatial accessibility to primary care physicians. Health & place, 15(4), 1100-1107."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe14bd6-d94b-4192-a52c-668674e45955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
